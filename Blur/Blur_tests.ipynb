{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hans Walker\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import PIL\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sargan_models import SARGAN\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import skimage.measure as ski_me\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from cifar_helper import get_data, chunks\n",
    "from sar_utilities import add_gaussian_noise, preprocess_test\n",
    "from alert_utilities import send_images_via_email\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from pgd_attack import LinfPGDAttack\n",
    "from model import Model\n",
    "#import tensorflow_datasets as tfds\n",
    "with open('pgd/config.json') as config_file:\n",
    "    config = json.load(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224,224,1)\n",
    "trained_model_path = 'trained_models/sargan_mnist_gaussian_corrupted'\n",
    "BATCH_SIZE = 64\n",
    "NOISE_STD_RANGE = [0.1, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 1)\n",
      "INFO:tensorflow:Restoring parameters from trained_models/sargan_mnist_gaussian_corrupted\\sargan_mnist\n",
      "(64, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sargan_model=SARGAN(img_size, BATCH_SIZE, img_channel=1)\n",
    "image=np.load('testimage.NPY')\n",
    "newimage=np.zeros([28,28])\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        newimage[i,j]=image[10,i*28+j]\n",
    "newimage = PIL.Image.fromarray(newimage*255)\n",
    "transform=Resize((224,224))\n",
    "transform2=Resize((28,28))\n",
    "newimage= transform(newimage)\n",
    "newimage=np.array(newimage).reshape(1,224,224,1)\n",
    "imagebatch=np.zeros([64,224,224,1])\n",
    "imagebatch2=np.zeros([64,224,224,1])\n",
    "imagebatch[0]=newimage\n",
    "print(imagebatch.shape)\n",
    "with tf.Session() as sess:\n",
    "    saver= tf.train.Saver()\n",
    "    sargan_saver = tf.train.import_meta_graph(trained_model_path+'\\sargan_mnist.meta')\n",
    "    sargan_saver.restore(sess,tf.train.latest_checkpoint(trained_model_path))\n",
    "    imagebatch2 = gaussian_filter(np.array([add_gaussian_noise(imagebatch, sd=np.random.uniform(NOISE_STD_RANGE[0], NOISE_STD_RANGE[1]*10))]), sigma=2)\n",
    "    imagebatch2=imagebatch2.reshape((64, 224, 224, 1))\n",
    "    print(imagebatch2.reshape((64, 224, 224, 1)).shape)\n",
    "    gen_img = sess.run(sargan_model.gen_img,feed_dict={sargan_model.image: imagebatch, sargan_model.cond: imagebatch2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784)\n"
     ]
    }
   ],
   "source": [
    "image=np.load('testimage.NPY')\n",
    "print((image.shape))\n",
    "newbatch=image.reshape([200,28,28,1])\n",
    "#print(newimage.shape)\n",
    "newimage = torch.from_numpy(newbatch)\n",
    "newimage= transform(newimage)\n",
    "#newimage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hans Walker\\\\Desktop\\\\Hans the Awesome\\\\research\\\\adverserial\\\\Blur'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.66161723]\n",
      "  [ 0.63288684]\n",
      "  [ 0.63479557]\n",
      "  ...\n",
      "  [-0.64873736]\n",
      "  [-0.51696739]\n",
      "  [-0.08230452]]\n",
      "\n",
      " [[ 0.53192286]\n",
      "  [ 0.37492781]\n",
      "  [-0.21993874]\n",
      "  ...\n",
      "  [ 1.16431846]\n",
      "  [ 0.27044244]\n",
      "  [ 1.82052985]]\n",
      "\n",
      " [[ 0.99241565]\n",
      "  [-0.80039343]\n",
      "  [ 0.5086151 ]\n",
      "  ...\n",
      "  [-0.57598887]\n",
      "  [ 0.01022903]\n",
      "  [ 0.25040362]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.84682802]\n",
      "  [-0.22416307]\n",
      "  [ 0.50152838]\n",
      "  ...\n",
      "  [-0.07882573]\n",
      "  [-1.71340639]\n",
      "  [-0.12079074]]\n",
      "\n",
      " [[-1.1001386 ]\n",
      "  [ 0.55443364]\n",
      "  [-0.35943609]\n",
      "  ...\n",
      "  [ 0.46351164]\n",
      "  [ 0.72860994]\n",
      "  [ 0.32627173]]\n",
      "\n",
      " [[-0.6635486 ]\n",
      "  [-0.79256161]\n",
      "  [ 0.27732326]\n",
      "  ...\n",
      "  [-0.45064955]\n",
      "  [ 0.04858221]\n",
      "  [ 0.64657731]]]\n",
      "INFO:tensorflow:Restoring parameters from trained_models/sargan_mnist_gaussian_corrupted\\sargan_mnist\n",
      "[[-0.328371   -0.328371   -0.328371   ... -0.3957676  -0.3957676\n",
      "  -0.3957676 ]\n",
      " [-0.328371   -0.328371   -0.328371   ... -0.3957676  -0.3957676\n",
      "  -0.3957676 ]\n",
      " [-0.328371   -0.328371   -0.328371   ... -0.3957676  -0.3957676\n",
      "  -0.3957676 ]\n",
      " ...\n",
      " [-0.37163928 -0.37163928 -0.37163928 ... -0.31126943 -0.31126943\n",
      "  -0.31126943]\n",
      " [-0.37163928 -0.37163928 -0.37163928 ... -0.31126943 -0.31126943\n",
      "  -0.31126943]\n",
      " [-0.37163928 -0.37163928 -0.37163928 ... -0.31126943 -0.31126943\n",
      "  -0.31126943]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from model import Model\n",
    "from pgd_attack import LinfPGDAttack\n",
    "\n",
    "\n",
    "from sargan_models import SARGAN\n",
    "from sar_utilities import add_gaussian_noise, preprocess_test\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "import torch\n",
    "import numpy as np\n",
    "batch=np.load('testimage.NPY')\n",
    "\n",
    "from PIL import Image\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_size = (224,224,1)\n",
    "trained_model_path = 'trained_models/sargan_mnist_gaussian_corrupted'\n",
    "BATCH_SIZE = 64\n",
    "NOISE_STD_RANGE = [0.1, .9]\n",
    "    \n",
    "#sargan model\n",
    "#reshaping the images to a square\n",
    "newbatch=batch.reshape([len(batch),28,28])\n",
    "#upping the size of the image\n",
    "transform=Compose([ Resize((224, 224)), Normalize((np.mean(batch)), (np.std(batch),))])\n",
    "#creating the original batch\n",
    "transformed_batch=np.array(transform(torch.from_numpy(newbatch))).reshape([len(batch),224,224,1])\n",
    "#corrupting\n",
    "corruptedbatch=np.zeros([len(transformed_batch),224,224,1])\n",
    "for i in range(len(transformed_batch)):\n",
    "    #corruptedbatch[i]=gaussian_filter(np.array([add_gaussian_noise(transformed_batch[i], sd=np.random.uniform(NOISE_STD_RANGE[0], NOISE_STD_RANGE[1]))]), sigma=10)[0]\n",
    "    corruptedbatch[i]=np.array([add_gaussian_noise(transformed_batch[i], sd=np.random.uniform(NOISE_STD_RANGE[0], NOISE_STD_RANGE[1]))])[0]\n",
    "print(transformed_batch[0]-corruptedbatch[i])\n",
    "    #storage spaces for the prcoessed images\n",
    "cbatch=np.zeros([BATCH_SIZE,224,224,1])\n",
    "outbatch=np.zeros([len(batch),224,224])\n",
    "j=0\n",
    "k=0\n",
    "tf.reset_default_graph()\n",
    "sargan_model=SARGAN(img_size, BATCH_SIZE, img_channel=1)\n",
    "with tf.Session() as sess:\n",
    "    saver= tf.train.Saver()\n",
    "    sargan_saver = tf.train.import_meta_graph(trained_model_path+'\\sargan_mnist.meta')\n",
    "    sargan_saver.restore(sess,tf.train.latest_checkpoint(trained_model_path))\n",
    "    for i in range(len(batch)):\n",
    "        j+=1\n",
    "        cbatch[i%BATCH_SIZE]=corruptedbatch[i]\n",
    "        if((j%BATCH_SIZE==0) or ((i+1)%len(batch)==0)):\n",
    "            processed_batch=sess.run(sargan_model.gen_img,feed_dict={sargan_model.image: cbatch, sargan_model.cond: cbatch})\n",
    "            for l in range(j):\n",
    "                outbatch[k]=processed_batch[l,:,:,0]\n",
    "                k+=1\n",
    "            j=0\n",
    "transform2=Resize([28,28])\n",
    "outbatch=np.array(transform2(torch.from_numpy(outbatch)))\n",
    "outbatch=outbatch.reshape([len(batch),784])\n",
    "testbatch=outbatch\n",
    "testbatch=testbatch.reshape([len(testbatch),28,28])\n",
    "#upping the size of the image\n",
    "transform=Resize([224,224])\n",
    "#creating the original batch\n",
    "testbatch=np.array(transform(torch.from_numpy(testbatch))).reshape([len(batch),224,224,1])\n",
    "print(testbatch[0,:,:,0])\n",
    "Image.fromarray(testbatch[0,:,:,0]*255).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2=np.load('original_images.NPY')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_size = (224,224,1)\n",
    "trained_model_path = 'trained_models/sargan_mnist_gaussian_corrupted'\n",
    "BATCH_SIZE = 64\n",
    "NOISE_STD_RANGE = [0.1, .9]\n",
    "    \n",
    "#sargan model\n",
    "#reshaping the images to a square\n",
    "newbatch2=batch.reshape([len(batch2),28,28])\n",
    "#upping the size of the image\n",
    "transform2=Compose([ Resize((224, 224)), Normalize((np.mean(batch2)), (np.std(batch2),))])\n",
    "#creating the original batch\n",
    "transformed_batch2=np.array(transform(torch.from_numpy(newbatch2))).reshape([len(batch2),224,224,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatch=outbatch\n",
    "testbatch=testbatch.reshape([len(testbatch),28,28])\n",
    "#upping the size of the image\n",
    "transform=Resize([224,224])\n",
    "#creating the original batch\n",
    "testbatch=np.array(transform(torch.from_numpy(testbatch))).reshape([len(batch),224,224,1])\n",
    "Image.fromarray(transformed_batch2[0,:,:,0]*255).show()\n",
    "#Image.fromarray(corruptedbatch[0,:,:,0]*255).show()\n",
    "Image.fromarray(transformed_batch[0,:,:,0]*255).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#downgrading the transform\n",
    "outbatch2=outbatch\n",
    "#ncbatch=corruptedbatch\n",
    "print(type(outbatch2))\n",
    "#Image.fromarray(ncbatch[0,:,:,0]*255).show()\n",
    "#Image.fromarray(outbatch2[0]*255).show()\n",
    "transform2=Resize([28,28])\n",
    "Image.fromarray(outbatch2[0]*255).show()\n",
    "outbatch2=np.array(transform2(torch.from_numpy(outbatch2)))\n",
    "outbatch2=outbatch2.reshape([len(batch),784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatch=outbatch\n",
    "testbatch=testbatch.reshape([len(testbatch),28,28])\n",
    "#upping the size of the image\n",
    "transform=Resize([224,224])\n",
    "#creating the original batch\n",
    "testbatch=np.array(transform(torch.from_numpy(testbatch))).reshape([len(batch),224,224,1])\n",
    "Image.fromarray(testbatch[10,:,:,0]*-255).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.ones([200,200])*200\n",
    "Image.fromarray(image).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
